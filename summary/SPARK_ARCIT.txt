RESILIENT DISTRIBUTION DATASET:
The main abstraction Spark provides is a resilient distributed dataset (RDD), which is a collection of elements partitioned across the nodes of the cluster that can be operated on in parallel. 

STEPS:
create rdd
rdd transformation
action
results

SPARK ARCHITECTURE:
Spark context(drive node)
Cluster manager
Executers(worker)

DAG
WORD COUNT PROGRAM